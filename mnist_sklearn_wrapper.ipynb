{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "# sklean接口的包装器KerasClassifier，作为sklearn的分类器接口\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "# 穷搜所有特定的参数值选出最好的模型参数\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 类别的数目\n",
    "nb_classes = 10\n",
    "# 输入图像的维度\n",
    "img_rows, img_cols = 28, 28\n",
    "# 读取数据\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# 读取的数据不包含通道维，因此shape为(60000,28,28)\n",
    "# 为了保持和后端tensorflow的数据格式一致，将数据补上通道维\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "# 新的数据shape为 (60000,28,28,1)， 1代表通道是1，也就是灰阶图片\n",
    "# 指明输入数据的大小，便于后面搭建网络的第一层传入该参数\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "# 数据类型改为float32，单精度浮点数\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# 数据归一化（图像数据常用）\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "# 将类别标签转换为one-hot编码\n",
    "y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义配置卷积网络模型的函数\n",
    "def make_model(dense_layer_sizes, nb_filters, nb_conv, nb_pool):\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(nb_filters, nb_conv, nb_conv,\n",
    "                            border_mode='valid',\n",
    "                            input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(nb_filters, nb_conv, nb_conv))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    for layer_size in dense_layer_sizes:\n",
    "        model.add(Dense(layer_size))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adadelta',\n",
    "                  metrics=['accuracy'])\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "40000/40000 [==============================] - 14s - loss: 0.8058 - acc: 0.7335    \n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 10s - loss: 0.4620 - acc: 0.8545    \n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 10s - loss: 0.3958 - acc: 0.8747    \n",
      "19776/20000 [============================>.] - ETA: 0sEpoch 1/3\n",
      "40000/40000 [==============================] - 11s - loss: 0.9589 - acc: 0.6804    \n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 10s - loss: 0.5885 - acc: 0.8116    \n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 10s - loss: 0.5021 - acc: 0.8429    \n",
      "19488/20000 [============================>.] - ETA: 0sEpoch 1/3\n",
      "40000/40000 [==============================] - 11s - loss: 0.9141 - acc: 0.6958    \n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 10s - loss: 0.5716 - acc: 0.8136    \n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 10s - loss: 0.4515 - acc: 0.8547    \n",
      "19584/20000 [============================>.] - ETA: 0sEpoch 1/6\n",
      "40000/40000 [==============================] - 11s - loss: 0.8968 - acc: 0.6983    \n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 10s - loss: 0.5692 - acc: 0.8130    \n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 10s - loss: 0.4600 - acc: 0.8494    \n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 10s - loss: 0.4091 - acc: 0.8694    \n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 10s - loss: 0.3717 - acc: 0.8790    \n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 10s - loss: 0.3461 - acc: 0.8898    \n",
      "20000/20000 [==============================] - 1s     \n",
      "Epoch 1/6\n",
      "40000/40000 [==============================] - 11s - loss: 0.8089 - acc: 0.7310    \n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 10s - loss: 0.4770 - acc: 0.8498    \n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 10s - loss: 0.4086 - acc: 0.8704    \n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 10s - loss: 0.3657 - acc: 0.8860    \n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 10s - loss: 0.3383 - acc: 0.8938    \n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 10s - loss: 0.3164 - acc: 0.9027    \n",
      "19520/20000 [============================>.] - ETA: 0sEpoch 1/6\n",
      "40000/40000 [==============================] - 11s - loss: 0.8393 - acc: 0.7214    \n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 10s - loss: 0.5132 - acc: 0.8379    \n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 10s - loss: 0.4331 - acc: 0.8635    \n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 10s - loss: 0.3813 - acc: 0.8808    \n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 10s - loss: 0.3530 - acc: 0.8902    \n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 10s - loss: 0.3278 - acc: 0.8986    \n",
      "19936/20000 [============================>.] - ETA: 0sEpoch 1/3\n",
      "40000/40000 [==============================] - 11s - loss: 0.5975 - acc: 0.8099    \n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 10s - loss: 0.3181 - acc: 0.9048    \n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 10s - loss: 0.2673 - acc: 0.9199    \n",
      "19808/20000 [============================>.] - ETA: 0sEpoch 1/3\n",
      "40000/40000 [==============================] - 11s - loss: 0.6155 - acc: 0.8040    \n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 11s - loss: 0.3500 - acc: 0.8951    \n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 11s - loss: 0.2864 - acc: 0.9156    \n",
      "20000/20000 [==============================] - 1s     \n",
      "Epoch 1/3\n",
      "40000/40000 [==============================] - 11s - loss: 0.7519 - acc: 0.7560    \n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 10s - loss: 0.4660 - acc: 0.8580    \n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 10s - loss: 0.3553 - acc: 0.8936    \n",
      "19776/20000 [============================>.] - ETA: 0sEpoch 1/6\n",
      "40000/40000 [==============================] - 11s - loss: 0.5869 - acc: 0.8162    \n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 11s - loss: 0.3279 - acc: 0.9014    \n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 11s - loss: 0.2725 - acc: 0.9187    \n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 11s - loss: 0.2366 - acc: 0.9291    \n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 11s - loss: 0.2102 - acc: 0.9386    \n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 16s - loss: 0.1954 - acc: 0.9423    \n",
      "19840/20000 [============================>.] - ETA: 0sEpoch 1/6\n",
      "40000/40000 [==============================] - 11s - loss: 0.5526 - acc: 0.8262    \n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 11s - loss: 0.2903 - acc: 0.9142    \n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 11s - loss: 0.2361 - acc: 0.9302    \n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 11s - loss: 0.2064 - acc: 0.9396    \n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 10s - loss: 0.1886 - acc: 0.9443    \n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 10s - loss: 0.1755 - acc: 0.9496    \n",
      "19808/20000 [============================>.] - ETA: 0sEpoch 1/6\n",
      "40000/40000 [==============================] - 11s - loss: 0.7275 - acc: 0.7677    \n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 10s - loss: 0.4141 - acc: 0.8772    \n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 10s - loss: 0.3136 - acc: 0.9056    \n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 10s - loss: 0.2651 - acc: 0.9210    \n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 10s - loss: 0.2363 - acc: 0.9306    \n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 10s - loss: 0.2092 - acc: 0.9380    \n",
      "19552/20000 [============================>.] - ETA: 0sEpoch 1/3\n",
      "40000/40000 [==============================] - 12s - loss: 0.7849 - acc: 0.7334    \n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 11s - loss: 0.4506 - acc: 0.8587    \n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 11s - loss: 0.3741 - acc: 0.8813    \n",
      "19872/20000 [============================>.] - ETA: 0sEpoch 1/3\n",
      "40000/40000 [==============================] - 12s - loss: 0.8744 - acc: 0.7068    \n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 11s - loss: 0.5231 - acc: 0.8312    \n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 11s - loss: 0.4305 - acc: 0.8635    \n",
      "19552/20000 [============================>.] - ETA: 0sEpoch 1/3\n",
      "40000/40000 [==============================] - 12s - loss: 0.7567 - acc: 0.7473    \n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 11s - loss: 0.4200 - acc: 0.8685    \n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 11s - loss: 0.3604 - acc: 0.8887    \n",
      "19712/20000 [============================>.] - ETA: 0sEpoch 1/6\n",
      "40000/40000 [==============================] - 12s - loss: 0.7111 - acc: 0.7676    \n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 11s - loss: 0.4243 - acc: 0.8669    \n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 11s - loss: 0.3638 - acc: 0.8873    \n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 11s - loss: 0.3223 - acc: 0.8995    \n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 11s - loss: 0.2994 - acc: 0.9073    \n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 11s - loss: 0.2823 - acc: 0.9135    \n",
      "20000/20000 [==============================] - 2s     \n",
      "Epoch 1/6\n",
      "40000/40000 [==============================] - 12s - loss: 0.7588 - acc: 0.7513    \n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 11s - loss: 0.4568 - acc: 0.8570    \n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 12s - loss: 0.3757 - acc: 0.8819    \n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 11s - loss: 0.3256 - acc: 0.8969    \n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 11s - loss: 0.2996 - acc: 0.9060    \n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 11s - loss: 0.2702 - acc: 0.9146    \n",
      "19904/20000 [============================>.] - ETA: 0sEpoch 1/6\n",
      "40000/40000 [==============================] - 12s - loss: 0.7798 - acc: 0.7464    \n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 11s - loss: 0.4625 - acc: 0.8571    \n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 11s - loss: 0.3869 - acc: 0.8814    \n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 11s - loss: 0.3429 - acc: 0.8959    \n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 11s - loss: 0.3143 - acc: 0.9035    \n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 11s - loss: 0.2889 - acc: 0.9122    \n",
      "19840/20000 [============================>.] - ETA: 0sEpoch 1/3\n",
      "40000/40000 [==============================] - 13s - loss: 0.5828 - acc: 0.8161    \n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 11s - loss: 0.3009 - acc: 0.9099    \n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 11s - loss: 0.2393 - acc: 0.9291    \n",
      "19680/20000 [============================>.] - ETA: 0sEpoch 1/3\n",
      "40000/40000 [==============================] - 12s - loss: 0.5584 - acc: 0.8246    \n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 12s - loss: 0.2862 - acc: 0.9152    \n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 11s - loss: 0.2334 - acc: 0.9319    \n",
      "19488/20000 [============================>.] - ETA: 0sEpoch 1/3\n",
      "40000/40000 [==============================] - 13s - loss: 0.6253 - acc: 0.8020    \n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 11s - loss: 0.3054 - acc: 0.9093    \n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 12s - loss: 0.2463 - acc: 0.9278    \n",
      "19808/20000 [============================>.] - ETA: 0sEpoch 1/6\n",
      "40000/40000 [==============================] - 13s - loss: 0.5753 - acc: 0.8200    \n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 12s - loss: 0.2827 - acc: 0.9170    \n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 11s - loss: 0.2217 - acc: 0.9339    \n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 11s - loss: 0.1863 - acc: 0.9455    \n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 12s - loss: 0.1663 - acc: 0.9516    \n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 12s - loss: 0.1535 - acc: 0.9550    \n",
      "19680/20000 [============================>.] - ETA: 0sEpoch 1/6\n",
      "40000/40000 [==============================] - 13s - loss: 0.5670 - acc: 0.8247    \n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 12s - loss: 0.2728 - acc: 0.9204    \n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 12s - loss: 0.2134 - acc: 0.9383    \n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 12s - loss: 0.1890 - acc: 0.9459    \n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 12s - loss: 0.1695 - acc: 0.9501    \n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 12s - loss: 0.1570 - acc: 0.9535    \n",
      "19712/20000 [============================>.] - ETA: 0sEpoch 1/6\n",
      "40000/40000 [==============================] - 13s - loss: 0.6227 - acc: 0.7986    \n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 12s - loss: 0.3322 - acc: 0.9007    \n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 12s - loss: 0.2469 - acc: 0.9258    \n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 12s - loss: 0.2029 - acc: 0.9409    \n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 12s - loss: 0.1748 - acc: 0.9496    \n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 12s - loss: 0.1558 - acc: 0.9542    \n",
      "19872/20000 [============================>.] - ETA: 0sEpoch 1/6\n",
      "60000/60000 [==============================] - 19s - loss: 0.4922 - acc: 0.8482    \n",
      "Epoch 2/6\n",
      "60000/60000 [==============================] - 24s - loss: 0.2342 - acc: 0.9318    \n",
      "Epoch 3/6\n",
      "60000/60000 [==============================] - 24s - loss: 0.1843 - acc: 0.9485    \n",
      "Epoch 4/6\n",
      "60000/60000 [==============================] - 25s - loss: 0.1556 - acc: 0.9549    \n",
      "Epoch 5/6\n",
      "60000/60000 [==============================] - 24s - loss: 0.1450 - acc: 0.9581    \n",
      "Epoch 6/6\n",
      "60000/60000 [==============================] - 25s - loss: 0.1312 - acc: 0.9624    \n",
      "Yhe parameters of the best model are: \n",
      "{'nb_conv': 3, 'nb_epoch': 6, 'nb_pool': 2, 'dense_layer_sizes': [64, 64], 'nb_filters': 8}\n"
     ]
    }
   ],
   "source": [
    "# 全连接层的备选参数列表\n",
    "dense_size_candidates = [[32], [64], [32, 32], [64, 64]]\n",
    "# 实现为Keras准备的sklearn分类器接口，创建一个分类器/评估器对象\n",
    "# 传入的参数为：\n",
    "# build_fn: callable function or class instance\n",
    "# **sk_params: model parameters & fitting parameters\n",
    "# 具体分析如下：\n",
    "# 传入的第一个参数(build_fn)为可回调的函数，该函数建立、配置并返回一个Keras model，\n",
    "# 该model将被用来训练/预测，这里我们传入了刚刚定义好的make_model函数\n",
    "# 传入的第二个参数(**sk_params)为关键字参数(关键字参数在函数内部自动组装为一个dict),\n",
    "# 既可以是模型的参数，也可以是训练的参数，合法的模型参数就是build_fn的参数，\n",
    "# 注意，像所有sklearn中其他的评估器(estimator)一样，build_fn应当为其参数提供默认值，\n",
    "# 以便我们在建立estimator的时候不用向sk_params传入任何值。\n",
    "# sk_params也可以接收用来调用fit/predict/predict_proba/score方法的参数，\n",
    "# 例如'nb_epoch','batch_size'\n",
    "# fit/predict/predict_proba/score方法的参数将会优先从传入fit/predict/predict_proba/score\n",
    "# 的字典参数中选择，其次才从传入sk_params的参数中选，最后才选择keras的Sequential模型的默认参数中选择\n",
    "# 这里我们传入了用于调用fit方法的batch_size参数\n",
    "my_classifier = KerasClassifier(make_model, batch_size=32)\n",
    "# 当调用sklearn的grid_search接口时，合法的可调参数就是传给sk_params的参数，包括训练参数\n",
    "# 换句话说，就是可以用grid_search来选择最佳的batch_size/nb_epoch，或者其他的一些模型参数\n",
    "\n",
    "# GridSearchCV类，穷搜(Exhaustive search)评估器中所有特定的参数，\n",
    "# 其重要的两类方法为fit和predict\n",
    "# 传入参数为评估器对象my_classifier，由每一个grid point实例化一个estimator\n",
    "# 参数网格param_grid，类型为dict，需要尝试的参数名称以及对应的数值\n",
    "# 评估方式scoring，这里采用对数损失来评估\n",
    "validator = GridSearchCV(my_classifier,\n",
    "                         param_grid={'dense_layer_sizes': dense_size_candidates,\n",
    "                                     'nb_epoch': [3,6],\n",
    "                                     'nb_filters': [8],\n",
    "                                     'nb_conv': [3],\n",
    "                                     'nb_pool': [2]},\n",
    "                         scoring='log_loss')\n",
    "# 根据各个参数值的不同组合在(X_train, y_train)上训练模型\n",
    "validator.fit(X_train, y_train)\n",
    "# 打印出训练过程中找到的最佳参数\n",
    "print('Yhe parameters of the best model are: ')\n",
    "print(validator.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9984/10000 [============================>.] - ETA: 0s\n",
      "loss :  0.0550105490824\n",
      "acc :  0.9826\n"
     ]
    }
   ],
   "source": [
    "# validator.best_estimator_返回sklearn-warpped版本的最佳模型\n",
    "# validator.best_estimator_.model返回未包装的最佳模型\n",
    "best_model = validator.best_estimator_.model\n",
    "# 度量值的名称\n",
    "metric_names = best_model.metrics_names \n",
    "# metric_names = ['loss', 'acc']\n",
    "# 度量值的数值\n",
    "metric_values = best_model.evaluate(X_test, y_test)\n",
    "# metric_values = [0.0550, 0.9826]\n",
    "print()\n",
    "for metric, value in zip(metric_names, metric_values):\n",
    "    print(metric, ': ', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
