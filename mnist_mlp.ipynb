{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "# 导入numpy库， numpy是一个常用的科学计算库，优化矩阵的运算\n",
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "\n",
    "# 导入mnist数据库， mnist是常用的手写数字库\n",
    "from keras.datasets import mnist\n",
    "# 导入顺序模型\n",
    "from keras.models import Sequential\n",
    "# 导入全连接层Dense， 激活层Activation 以及 Dropout层\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "# 导入优化器RMSProp\n",
    "from keras.optimizers import RMSprop\n",
    "# 导入numpy工具，主要是用to_categorical来转换类别向量\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 设置batch的大小\n",
    "batch_size = 128\n",
    "# 设置类别的个数\n",
    "nb_classes = 10\n",
    "# 设置迭代的次数\n",
    "nb_epoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# keras中的mnist数据集已经被划分成了60,000个训练集，10,000个测试集的形式，按以下格式调用即可\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# X_train原本是一个60000*28*28的三维向量，将其转换为60000*784的二维向量\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "# X_test原本是一个10000*28*28的三维向量，将其转换为10000*784的二维向量\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "# 将X_train, X_test的数据格式转为float32存储\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# 归一化\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "# 打印出训练集和测试集的信息\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "将类别向量(从0到nb_classes的整数向量)映射为二值类别矩阵，\n",
    "相当于将向量用one-hot重新编码\n",
    "'''\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_4 (Dense)                  (None, 512)           401920      dense_input_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 512)           0           dense_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 512)           0           activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 512)           262656      dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 512)           0           dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 512)           0           activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 10)            5130        dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 10)            0           dense_6[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 建立序贯模型\n",
    "model = Sequential()\n",
    "'''\n",
    "模型需要知道输入数据的shape，\n",
    "因此，Sequential的第一层需要接受一个关于输入数据shape的参数，\n",
    "后面的各个层则可以自动推导出中间数据的shape，\n",
    "因此不需要为每个层都指定这个参数\n",
    "''' \n",
    "\n",
    "# 输入层有784个神经元\n",
    "# 第一个隐层有512个神经元，激活函数为ReLu，Dropout比例为0.2\n",
    "model.add(Dense(512, input_shape=(784,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# 第二个隐层有512个神经元，激活函数为ReLu，Dropout比例为0.2\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# 输出层有10个神经元，激活函数为Softmax，得到分类结果\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# 输出模型的参数信息\n",
    "# 总共参数数量为784*512+512 + 512*512+512 + 512*10+10 = 669706\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s - loss: 0.2468 - acc: 0.9245 - val_loss: 0.1062 - val_acc: 0.9662\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s - loss: 0.1027 - acc: 0.9687 - val_loss: 0.0885 - val_acc: 0.9744\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s - loss: 0.0755 - acc: 0.9772 - val_loss: 0.0798 - val_acc: 0.9763\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s - loss: 0.0617 - acc: 0.9810 - val_loss: 0.1023 - val_acc: 0.9692\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s - loss: 0.0512 - acc: 0.9847 - val_loss: 0.0832 - val_acc: 0.9791\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s - loss: 0.0447 - acc: 0.9866 - val_loss: 0.0778 - val_acc: 0.9796\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s - loss: 0.0392 - acc: 0.9883 - val_loss: 0.0822 - val_acc: 0.9798\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s - loss: 0.0336 - acc: 0.9899 - val_loss: 0.0784 - val_acc: 0.9820\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s - loss: 0.0336 - acc: 0.9904 - val_loss: 0.0937 - val_acc: 0.9809\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s - loss: 0.0293 - acc: 0.9917 - val_loss: 0.0802 - val_acc: 0.9829\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s - loss: 0.0260 - acc: 0.9924 - val_loss: 0.0966 - val_acc: 0.9821\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s - loss: 0.0240 - acc: 0.9932 - val_loss: 0.0984 - val_acc: 0.9836\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s - loss: 0.0230 - acc: 0.9939 - val_loss: 0.1032 - val_acc: 0.9822\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s - loss: 0.0236 - acc: 0.9933 - val_loss: 0.1002 - val_acc: 0.9843\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s - loss: 0.0184 - acc: 0.9945 - val_loss: 0.1111 - val_acc: 0.9811\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s - loss: 0.0201 - acc: 0.9944 - val_loss: 0.0982 - val_acc: 0.9837\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s - loss: 0.0186 - acc: 0.9949 - val_loss: 0.1012 - val_acc: 0.9841\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s - loss: 0.0179 - acc: 0.9951 - val_loss: 0.1132 - val_acc: 0.9824\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s - loss: 0.0189 - acc: 0.9950 - val_loss: 0.1081 - val_acc: 0.9842\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s - loss: 0.0168 - acc: 0.9956 - val_loss: 0.1109 - val_acc: 0.9837\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "配置模型的学习过程\n",
    "compile接收三个参数：\n",
    "1.优化器optimizer：参数可指定为已预定义的优化器名，如rmsprop、adagrad，\n",
    "或一个Optimizer类对象，如此处的RMSprop()\n",
    "2.损失函数loss：参数为模型试图最小化的目标函数，可为预定义的损失函数，\n",
    "如categorical_crossentropy、mse，也可以为一个损失函数\n",
    "3.指标列表：对于分类问题，一般将该列表设置为metrics=['accuracy']\n",
    "'''\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "'''\n",
    "训练模型\n",
    "batch_size：指定梯度下降时每个batch包含的样本数\n",
    "nb_epoch：训练的轮数，nb指number of\n",
    "verbose：日志显示，0为不在标准输出流输出日志信息，1为输出进度条记录，2为epoch输出一行记录\n",
    "validation_data：指定验证集\n",
    "fit函数返回一个History的对象，其History.history属性记录了损失函数和其他指标的数值随epoch变化的情况，\n",
    "如果有验证集的话，也包含了验证集的这些指标变化情况\n",
    "'''\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size = batch_size,\n",
    "                    nb_epoch = nb_epoch,\n",
    "                    verbose = 1,\n",
    "                    validation_data = (X_test, Y_test))\n",
    "\n",
    "# 按batch计算在某些输入数据上模型的误差\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.110892460335\n",
      "Test accuracy: 0.9837\n"
     ]
    }
   ],
   "source": [
    "# 输出训练好的模型在测试集上的表现\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
